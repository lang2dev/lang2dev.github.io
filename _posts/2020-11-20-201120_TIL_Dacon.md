---
title: 201120_TIL_Dacon
categories: TIL dacon
tags: dacon NLP
last_modified_at: 2020-11-20 17:00:00 -0500
---

## Dacon Author Classfication 1일차

* 미루고 미루던 Dacon 과제를 해보았다. 


* 링크: [Dacon 소설 작가 분류 AI 경진대회](https://dacon.io/competitions/official/235670/overview/)


* 영미 소설 데이터를 바탕으로 작가의 문체를 구분하는 문제이다. 어려워 보이지만, **카테고리 분류**의 영역이라고 할 수 있다. 넓게 보면 결국 청와대 청원 분류와 비슷한 task이다.


* colab 환경에서 함.


* train 데이터는 총 54879개의 샘플, test 데이터는 19617개의 샘플.

## Kaggle에서 Classfication 공부

* 우선 카테고리 분류 예시 코드를 보아야겠다고 생각했다.


* Kaggle에서 카테고리 분류 코드를 보았음. 아래는 참고한 노트북들.


* [A Complete Text Classfication Guide](https://www.kaggle.com/rajmehra03/a-complete-text-classfication-guide-word2vec-lstm)


* [Simple Feature Engg Notebook - Spooky Author](https://www.kaggle.com/sudalairajkumar/simple-feature-engg-notebook-spooky-author)


* 두 번째 notebook은 Author Classfication문제. 여기서 인상 깊었던 것은, Feature List를 뽑은 것이다. 텍스트의 길이, 단어의 길이, 대문자의 개수, 소문자의 개수 등 나올 수 있는 모든 Feature들을 뽑았다.

## 전처리

* 불용어 지정


* 특수문자를 삭제할것인지 : 이 텍스트는 소설이다. 특수문자로 문장의 호흡을 짧게 끊는 것도 작가의 특징이 될 수 있다.


* 상위 데이터 10개 정도를 보고 판단한 **유의미한** 특수문자 : .(온점) , (반점) ?(물음표), !(느낌표) 


* 결론: 모든 텍스트와 네 가지 특수문자를 남기기로 하였다. 일반 Task와는 다르게 최대한 원본과 비슷하게 처리하려고 하였다.


* 불용어 목록을 최소한으로 하였다. 전치사, be동사 중심으로 제거. 문체는 '특정 키워드'를 뽑아내는 Task가 아니라고 판단.


* 모두 내 **직관**에 따라 판단하고 전처리한 것임. 나중에 객관적인 확인 필요.
  

## 모델 학습

* 전처리까지 하고 나니 엄청 지쳤다. 남은 모델 학습은 내일 마저 하자...
 
 
* 궁금해서 Dacon에서 제공해준 Baseline 코드로 모델 학습을 해보았다.
 
 
* 점수는 0.56527(Loss)이다. 한마디로 **형편없다 ^^**


* 10점대로 나오는 분들은 어떻게 한거지...?

 
* 코드 공개 하기도 민망한 점수이다.

## 1일차 느낀점

* 일단 한국어가 아니라 그런가 ... 사람이 수행한다고 해도 어려울 것 같은 task로 느껴졌음.


* 전처리까지는 어떻게 하겠는데 모델 학습 부분이 아직도 너무 어렵다. Kagge Notebook을 읽어도 잘 이해가 안 된다. 😇 아 진짜 어떻게 공부하는거야 다들...
