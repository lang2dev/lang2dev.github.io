---
title: 200909_TIL
categories: TIL
tags:
last_modified_at: 2020-09-09 22:06:00 -0500
---
### 오늘 한 일

* '김기현의 자연어 처리 딥러닝 캠프' 5.5 부분공부하고, colab으로 실습했다.

* 오늘은 TF-IDF를 구현하는 실습을 해보았다. 실습해보니 내용이 너무 괜찮고 나중에도 잘 쓰일 수 있을 것 같다! 레포지터리에 저장해놔야겠다.

### 특징 벡터와 TF-IDF

* 특징 벡터를 위한 중요한 가정: 1) 의미가 비슷한 단어라면 쓰임새가 비슷할 것 2) 쓰임새가 비슷하므로, 비슷한 문장 안에서 비슷한 역할로 사용될 것 3) 따라서 함께 나타나는 단어들이 유사할 것

* TF는 term frequency로, 단어의 문서 내 출현 횟수이다. DF는 그 단어가 출현한 문서의 숫자이며, IDF는 DF에 역수를 취한 것이다. DF가 클수록 '흔한 단어'가 된다. (the, a ... 같은 단어) 우리는 TF에 IDF를 곱함으로써 특정 단어가 문서에서 얼마나 중요한 역할을 차지하는지 수치를 확인할 수 있다. 수치가 높은 것은 "이 단어는 다른 문서에서는 잘 등장하지 않지만, 이 문서에서는 잘 등장합니다"를 의미하기 때문이다.
