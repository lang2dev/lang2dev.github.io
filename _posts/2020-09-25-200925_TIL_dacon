## 오늘 한 일

* 어제(24일)~오늘(25일) Dacon 데이터를 다시 돌려보았다. 토요일 스터디에서 조언받은대로 1) word2vec 임베딩 적용해보기 2) validation data 나누기 3) 과적합 방지하기 세 가지를 해보았음. 

* **그러나 세 가지 모두 시원찮았다** :thinking_face:

### word2vec 임베딩

* word2vec 임베딩을 데이터에 한번 적용해봤다. <딥 러닝을 이용한 자연어 처리 입문>을 참고하였음.

```python
from gensim.models import Word2Vec
model = Word2Vec(sentences = X_train, size = 500, window = 5, min_count = 5, workers = 4, sg = 0)
# 완성된 임베딩 매트릭스의 크기 확인
model.wv.vectors.shape
print(model.wv.most_similar("정책"))
# [('시책', 0.6108055114746094), ('탁상공론', 0.572714626789093), ('대책', 0.5559360980987549), ('대안', 0.534482479095459), ('방향', 0.5309896469116211), ('장려', 0.5279293656349182), ('제도', 0.5028440356254578), ('방침', 0.5023252964019775),
print(model.wv.most_similar("청년"))
# [('젊은이', 0.7140879034996033), ('젊다', 0.6664850115776062), ('청춘', 0.6436769962310791), ('실업률', 0.609180212020874), ('대학생', 0.5673409104347229)
print(model.wv.most_similar("여성"))
# [('남성', 0.7754548192024231), ('남성은', 0.6327731609344482), ('여성인권', 0.5603541731834412), ('남녀평등', 0.5527241230010986), ('역차별', 0.5448805093765259)
```


* 잘 학습되었음. 재미있었던 것은 **'정책'**하고 가까운 단어가 **'탁상공론'**이라는 것, **'청년'**하고 가까운 단어가 **'실업률'**이라는 것... 하하

* 다른 문서는 또 어떻게 나올지 궁금해졌다.

* 실습 코드 따라한 수준이라 더 자세히 공부해야겠음.

### validation data 나누기

* 이건 실패했다. 이유를 지금도 못 찾은 상태...

```python
from sklearn.model_selection import train_test_split
x_train, x_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)
```

* 이 코드를 중간에 추가했더니 모델 학습 과정에서 오류가 발생하였다. X_train 과 y_train의 개수가 맞지 않아서 학습을 못한다는 내용...!!!
* 아래처럼 오류가 났다.

> ValueError: Data cardinality is ambiguous: 
>
> x sizes: 39362  y sizes: 31489

* `print(X_train.shape, y_train.shape)`을 찍어보니 둘이 다른 사이즈로 나왔음... 대체 왜...! 혹시 중간에 잘못한 거 있는가 싶어서 두 세번 더 돌려봤는데 valid data를 나누는 과정에서 문제가 있는 게 맞는듯하다... :thinking_face::thinking_face: 대체 왜지

### 과적합 방지하기

* 지난 시간 Dacon 모델을 학습시켰을 때 문제는 과적합이었다. 모델이 test_data에서는 굉장히 높은 성능을 보였는데(90점 이상) 실제 데이터에서는 83점을 받은 것! 그래서 이를 방지하기 위해 중간에 이런 코드를 추가했다.

```python
model.add(Dropout(0.5))
```

* 학습할 때 무작위로 뉴런의 50%를 dropout(제외) 한다는 의미임.

* 결과는? 33점 나옴. 
* ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ

* 대체 뭐가 문제지
* 인생은 실전이다. 이런건가???

* 아... 모르겠다. 공부 다시 하고 오자
