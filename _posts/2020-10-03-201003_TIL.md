---
title: 201003_TIL_dacon
categories: NLP
tags: NLP dacon
last_modified_at: 2020-10-03 12:32:00 -0500
---
## 오늘 한 일

* 지난 시간 문제가 생겼던 세 가지 1) Word2Vec 모델로 돌리고 싶은데 방법을 모르겠음 2) validation data를 나누었더니 shape 크기가 안맞음 3) 과적합 방지 적용했더니 정확도가 33점 나옴 을 해결하고자 하였다.

* 2가지는 해결했고 1가지는 아직 해결 못했다.

### 2) validation data

* 이건 굉장히 사소한 문제였다. 마지막 model 학습에서 x_train이라고 써야 하는데 X_train을 썼기 때문에 정답 길이가 맞지 않는 오류가 났던 것이다!

* 그래서 이 문제를 해결하고 나니 학습이 잘 되었고 아주 미묘하게 정답률이 올라갔다!

* 점수는 **83.06점**에서 **83.38점**으로 올라갔다.

* 아무래도 데이터 크기 자체가 작아서 그런지 드라마틱한 변화는 없었던 것 같다.

### 3) 과적합 방지

* 과적합 방지로 넣은 dropout이 실패한 이유는 모델의 제일 마지막에 코드를 넣었기 때문이다. 스터디원분께서 알려주신 건데, 이렇게 코드를 짜면 <u>답안지를 다 쓰고 나서 답안지를 반 찢은 다음 제출한 것과 같다</u> 고 설명해주셨다.😂😂

* 따라서 모델을 복잡하게 만드는 경우 사이사이 추가하는 코드이며, 내가 짠 코드는 엄청 간단해서 굳이 넣을 필요는 없을 것 같다.

### 1) Word2Vec

* 내가 생각했던 것: Word2Vec 모델이 가진 숫자(?)를 tokenizer 사전(모든 토큰화된 단어를 빈도수에 따라 1부터 55101까지 번호를 매김)에 일일이 대응해서 학습시키기.

* 그래서 key를 tokenizer의 단어로, value를 Word2Vec의 수치값으로 하는 딕셔너리를 만드는 반복문을 사용하려고 하였다.

* 그러나 문제가 발생하였다.

* **첫번째. tokenizer 사전의 모든 단어가 Word2Vec 단어 사전에 대응하지 않는다.** for문을 만들어서 돌려보니 다음과 같은 오류가 발생하였다: `word '턱턱' not in vocabulary` 이는 word2Vec에 '턱턱'이라는 단어가 없다는 것을 의미하는데

```python
tokenizer.word_index['턱턱']
# 24166
model['턱턱']
# KeyError: "word '턱턱' not in vocabulary"
```

* 위 코드로 확인해보니 tokenizer의 단어 사전에서 24166번째를 차지하는 '턱턱'은 Word2Vec model에는 없음을 확인할 수 있었다. 다른 단어도 임의로 해보니 상대적으로 출현횟수가 적어 tokenizer 단어 사전의 뒤에 위치할수록 Word2Vec model에 없다는 것을 확인하였다.

* **두번째, 계산량이 너무 많음** 생각해보면 dictionary 안에 (최소) 단어 10000개를 각각 어마어마한 양의 벡터 위치값을 넣는 것인데, 컴퓨터가 감당할 수 있을지 걱정이 되었다. (사실 이것도 잘 모르는 부분이긴 한데 돌리다보니 colab 상단의 RAM에 빨간줄이 떠서 이렇게 생각했다.)

* **세번째, 내가 너무 모른다** Word2Vec 모델을 만들어만 보았지 이 type을 어떻게 다루어야 할지, 어떻게 해야 Word2Vec 모델에서 단어 목록을 추출할 수 있는지, 이 모델을 활용해 딥러닝 모델을 학습시킬 수 있는지, 그게 효과적인지!!! 아는 게 없다. 🤯

* 그래서 Word2Vec은 해결하지 못했다.

## 앞으로의 계획

* 일단은 Dacon 데이터는 둔다. 더 수련해서 올 것이다.

* 모델을 복잡하게 만들기보다 데이터를 정제하는데 신경을 써봐야겠다. 특히 귓등으로 들어 조금만 알고 있었던 Word2Vec에 대해서 구조, 원리를 공부해보아야겠다.

* 스터디원들과 새로운 프로젝트(?)를 할 것 같다. 그 과정에서 또 배움이 있기를 바란다.
